<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Methods for Causal Inference | Introduction To Causality: A Modern Approach</title>
  <meta name="description" content="A gentle introduction into the art and science of causal inference" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Methods for Causal Inference | Introduction To Causality: A Modern Approach" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://flobrez.github.io/intro_to_causality/" />
  <meta property="og:image" content="https://flobrez.github.io/intro_to_causality/images/cover.png" />
  <meta property="og:description" content="A gentle introduction into the art and science of causal inference" />
  <meta name="github-repo" content="flobrez/itc" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Methods for Causal Inference | Introduction To Causality: A Modern Approach" />
  
  <meta name="twitter:description" content="A gentle introduction into the art and science of causal inference" />
  <meta name="twitter:image" content="https://flobrez.github.io/intro_to_causality/images/cover.png" />

<meta name="author" content="Florian Brezina" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="causal-models.html"/>
<link rel="next" href="applications.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="itc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Introduction To Causality</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#what-you-will-learn"><i class="fa fa-check"></i><b>1.1</b> What you will learn</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#what-you-wont-learn"><i class="fa fa-check"></i><b>1.2</b> What you won’t learn</a><ul>
<li class="chapter" data-level="1.2.1" data-path="introduction.html"><a href="introduction.html#statistics"><i class="fa fa-check"></i><b>1.2.1</b> Statistics</a></li>
<li class="chapter" data-level="1.2.2" data-path="introduction.html"><a href="introduction.html#machine-learning"><i class="fa fa-check"></i><b>1.2.2</b> Machine Learning</a></li>
<li class="chapter" data-level="1.2.3" data-path="introduction.html"><a href="introduction.html#proofs"><i class="fa fa-check"></i><b>1.2.3</b> Proofs</a></li>
<li class="chapter" data-level="1.2.4" data-path="introduction.html"><a href="introduction.html#type-causality-vs-actual-causality"><i class="fa fa-check"></i><b>1.2.4</b> Type Causality vs Actual Causality</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#how-this-book-is-organised"><i class="fa fa-check"></i><b>1.3</b> How this book is organised</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#prerequisites"><i class="fa fa-check"></i><b>1.4</b> Prerequisites</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#acknowledgements"><i class="fa fa-check"></i><b>1.5</b> Acknowledgements</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#links"><i class="fa fa-check"></i><b>1.6</b> Links</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="causal-models.html"><a href="causal-models.html"><i class="fa fa-check"></i><b>2</b> Causal Models</a><ul>
<li class="chapter" data-level="2.1" data-path="causal-models.html"><a href="causal-models.html#causality-asymmetry-and-entropy"><i class="fa fa-check"></i><b>2.1</b> Causality, Asymmetry and Entropy</a></li>
<li class="chapter" data-level="2.2" data-path="causal-models.html"><a href="causal-models.html#basic-definitions"><i class="fa fa-check"></i><b>2.2</b> Basic Definitions</a><ul>
<li class="chapter" data-level="2.2.1" data-path="causal-models.html"><a href="causal-models.html#causal-graphs"><i class="fa fa-check"></i><b>2.2.1</b> Causal Graphs</a></li>
<li class="chapter" data-level="2.2.2" data-path="causal-models.html"><a href="causal-models.html#structural-equations"><i class="fa fa-check"></i><b>2.2.2</b> Structural Equations</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="causal-models.html"><a href="causal-models.html#deterministic-systems"><i class="fa fa-check"></i><b>2.3</b> Deterministic Systems</a><ul>
<li class="chapter" data-level="2.3.1" data-path="causal-models.html"><a href="causal-models.html#an-electric-circuit-with-one-switch"><i class="fa fa-check"></i><b>2.3.1</b> An electric circuit with one switch</a></li>
<li class="chapter" data-level="2.3.2" data-path="causal-models.html"><a href="causal-models.html#an-electric-circuit-with-two-switches"><i class="fa fa-check"></i><b>2.3.2</b> An electric circuit with two switches</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="causal-models.html"><a href="causal-models.html#unobservability"><i class="fa fa-check"></i><b>2.4</b> Unobservability</a><ul>
<li class="chapter" data-level="2.4.1" data-path="causal-models.html"><a href="causal-models.html#probabilistic-models-of-causality"><i class="fa fa-check"></i><b>2.4.1</b> Probabilistic Models of Causality</a></li>
<li class="chapter" data-level="2.4.2" data-path="causal-models.html"><a href="causal-models.html#interventions-more-generally-defined"><i class="fa fa-check"></i><b>2.4.2</b> Interventions More Generally Defined</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="causal-models.html"><a href="causal-models.html#probabilistic-systems"><i class="fa fa-check"></i><b>2.5</b> Probabilistic Systems</a><ul>
<li class="chapter" data-level="2.5.1" data-path="causal-models.html"><a href="causal-models.html#an-electric-circuit-with-two-switches-one-unobserved"><i class="fa fa-check"></i><b>2.5.1</b> An electric circuit with two switches, one unobserved</a></li>
<li class="chapter" data-level="2.5.2" data-path="causal-models.html"><a href="causal-models.html#section"><i class="fa fa-check"></i><b>2.5.2</b> </a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="causal-models.html"><a href="causal-models.html#causal-effects"><i class="fa fa-check"></i><b>2.6</b> Causal Effects</a><ul>
<li class="chapter" data-level="2.6.1" data-path="causal-models.html"><a href="causal-models.html#definition"><i class="fa fa-check"></i><b>2.6.1</b> Definition</a></li>
<li class="chapter" data-level="2.6.2" data-path="causal-models.html"><a href="causal-models.html#causal-effect-statistics"><i class="fa fa-check"></i><b>2.6.2</b> Causal Effect Statistics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html"><i class="fa fa-check"></i><b>3</b> Methods for Causal Inference</a><ul>
<li class="chapter" data-level="3.1" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#causal-vs-statistical-inference"><i class="fa fa-check"></i><b>3.1</b> Causal vs Statistical Inference</a><ul>
<li class="chapter" data-level="3.1.1" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#example-1-tutoring"><i class="fa fa-check"></i><b>3.1.1</b> Example 1 Tutoring</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#randomized-controlled-experiments"><i class="fa fa-check"></i><b>3.2</b> Randomized Controlled Experiments</a><ul>
<li class="chapter" data-level="3.2.1" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#assignment-mechanisms"><i class="fa fa-check"></i><b>3.2.1</b> Assignment Mechanisms</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#observational-data"><i class="fa fa-check"></i><b>3.3</b> Observational Data</a></li>
<li class="chapter" data-level="3.4" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#instrumental-variables"><i class="fa fa-check"></i><b>3.4</b> Instrumental Variables</a></li>
<li class="chapter" data-level="3.5" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#propensity-score-matching"><i class="fa fa-check"></i><b>3.5</b> Propensity Score Matching</a></li>
<li class="chapter" data-level="3.6" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#difference-in-difference-estimator"><i class="fa fa-check"></i><b>3.6</b> Difference-in-Difference Estimator</a></li>
<li class="chapter" data-level="3.7" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#time-series-methods"><i class="fa fa-check"></i><b>3.7</b> Time Series Methods</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>4</b> Applications</a><ul>
<li class="chapter" data-level="4.1" data-path="applications.html"><a href="applications.html#causality-and-machine-learning"><i class="fa fa-check"></i><b>4.1</b> Causality and Machine Learning</a></li>
<li class="chapter" data-level="4.2" data-path="applications.html"><a href="applications.html#marketing"><i class="fa fa-check"></i><b>4.2</b> Marketing</a></li>
<li class="chapter" data-level="4.3" data-path="applications.html"><a href="applications.html#drug-trial"><i class="fa fa-check"></i><b>4.3</b> Drug Trial</a></li>
<li class="chapter" data-level="4.4" data-path="applications.html"><a href="applications.html#discrimination"><i class="fa fa-check"></i><b>4.4</b> Discrimination</a></li>
<li class="chapter" data-level="4.5" data-path="applications.html"><a href="applications.html#epidemiology"><i class="fa fa-check"></i><b>4.5</b> Epidemiology</a><ul>
<li class="chapter" data-level="4.5.1" data-path="applications.html"><a href="applications.html#the-reporting-mechanism"><i class="fa fa-check"></i><b>4.5.1</b> The reporting mechanism</a></li>
<li class="chapter" data-level="4.5.2" data-path="applications.html"><a href="applications.html#evolving-symptoms"><i class="fa fa-check"></i><b>4.5.2</b> Evolving Symptoms</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="epistemology.html"><a href="epistemology.html"><i class="fa fa-check"></i><b>5</b> Epistemology</a><ul>
<li class="chapter" data-level="5.1" data-path="epistemology.html"><a href="epistemology.html#manipulation"><i class="fa fa-check"></i><b>5.1</b> Manipulation</a></li>
<li class="chapter" data-level="5.2" data-path="epistemology.html"><a href="epistemology.html#long-term-effects"><i class="fa fa-check"></i><b>5.2</b> Long-Term Effects</a></li>
<li class="chapter" data-level="5.3" data-path="epistemology.html"><a href="epistemology.html#are-all-sciences-equal"><i class="fa fa-check"></i><b>5.3</b> Are all sciences equal?</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="notation-and-terminology.html"><a href="notation-and-terminology.html"><i class="fa fa-check"></i><b>A</b> Notation and Terminology</a><ul>
<li class="chapter" data-level="A.1" data-path="notation-and-terminology.html"><a href="notation-and-terminology.html#terminology-confusion"><i class="fa fa-check"></i><b>A.1</b> Terminology Confusion</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="probabilistic-models-and-reasoning.html"><a href="probabilistic-models-and-reasoning.html"><i class="fa fa-check"></i><b>B</b> Probabilistic Models and Reasoning</a><ul>
<li class="chapter" data-level="B.1" data-path="probabilistic-models-and-reasoning.html"><a href="probabilistic-models-and-reasoning.html#probabilistic-reasoning"><i class="fa fa-check"></i><b>B.1</b> Probabilistic Reasoning</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>C</b> Statistical Inference</a><ul>
<li class="chapter" data-level="C.1" data-path="statistical-inference.html"><a href="statistical-inference.html#distributions"><i class="fa fa-check"></i><b>C.1</b> Distributions</a><ul>
<li class="chapter" data-level="C.1.1" data-path="statistical-inference.html"><a href="statistical-inference.html#single-random-variable"><i class="fa fa-check"></i><b>C.1.1</b> Single Random Variable</a></li>
<li class="chapter" data-level="C.1.2" data-path="statistical-inference.html"><a href="statistical-inference.html#multiple-random-variables"><i class="fa fa-check"></i><b>C.1.2</b> Multiple Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="statistical-inference.html"><a href="statistical-inference.html#statistical-inference-1"><i class="fa fa-check"></i><b>C.2</b> Statistical Inference</a><ul>
<li class="chapter" data-level="C.2.1" data-path="statistical-inference.html"><a href="statistical-inference.html#estimators"><i class="fa fa-check"></i><b>C.2.1</b> Estimators</a></li>
<li class="chapter" data-level="C.2.2" data-path="statistical-inference.html"><a href="statistical-inference.html#hypothesis-tests"><i class="fa fa-check"></i><b>C.2.2</b> Hypothesis Tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="code.html"><a href="code.html"><i class="fa fa-check"></i><b>D</b> Code</a><ul>
<li class="chapter" data-level="D.1" data-path="code.html"><a href="code.html#simulate-causal-models"><i class="fa fa-check"></i><b>D.1</b> Simulate Causal Models</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction To Causality: A Modern Approach</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="methods-for-causal-inference" class="section level1">
<h1><span class="header-section-number">3</span> Methods for Causal Inference</h1>
<p>Causal relations can be inferred from <strong>experiments</strong> as well as <strong>observational studies</strong>.
The randomized controlled experiment is a proven method to infer causal relations in complex environments. It involves full control over the assignment mechanism and the assignment is random.
A common variation is the situation where the variable of interest cannot be directly intervened on, but a causal parent can. For example, a doctor can (randomly) prescribe a certain drug, but the patient still chooses to take the drug or not. The method of instrumental variables allows us to infer (local) causal effects nevertheless.</p>
<p>Afterwards, we switch to those methods that can be used even if we cannot intervene in the environment, but have to rely on passive observation only. Inferring causal relations in these situations requires a thorough understanding of the causal links from the variable of interest to the effect. We will study two different inference strategies which rely on different sets of assumptions.</p>
<p>Finally, we discuss methods for causal inference in samples of size 1. Given appropriate assumptions, we are able to infer causal relations by leveraging (dependent) observations over time.</p>
<div id="causal-vs-statistical-inference" class="section level2">
<h2><span class="header-section-number">3.1</span> Causal vs Statistical Inference</h2>
<div class="figure">
<img src="images/hierarchy_statistical_vs_causal.png" alt="" />
<p class="caption">Causal vs Statistical Inference</p>
</div>
<p>Inferring causal mechansims from data is more difficult than learning about properties of the distribution of variables:</p>
<ul>
<li>Being able to infer causal mechanisms from data requires knowledge about the data generating process which cannot be inferred from the observed data itself. Observed data can help us justifying assumptions on the causal structure we are willing to accept, but it cannot fully specify the causal model in any application of interest. Hence, we will always have to incorporate (domain) knowledge to enrich the observed data before we can make causal inferences.</li>
<li>Causal inference does not get rid of the typical statistical problems. These are still there and need to be solved. The causal problems are just an additional layer on top.</li>
</ul>
<p>The causal structure implies statistical dependencies. If observations violate the implied dependencies, the causal structure cannot be correct. In practice, observing two variables to be statistically dependent these variables either have a common cause or they directly cause each other. There are practical limitations though:</p>
<ul>
<li><p>this only holds true for i.i.d. variables. if the observed data is a time series, this property does not hold. hence, time series observations might be statistically dependent, although there is no causal link. a common phenomenon is that two variables are <em>trending</em> over time. As an effect, observations from such time series will likely have a very high correlation, despite them being causally independent.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p></li>
<li><p>our ability to correctly infer statistical dependence might not be straightforward:</p>
<ul>
<li>if our analysis involves many variables, the number of tests necessary to establish conditional dependence between any pair of two variables increases swiftly. Maintaining a fixed type I error for independence will become exceedingly difficult. We may then falsely identify two variables as being dependent.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></li>
<li>we might not be able to observe (a random sample of) the outcomes of a causal mechanism, but only a biased one. this is commonly referred to as selection bias (or survivalship bias) in the literature. See also <a href="https://xkcd.com/1827/" class="uri">https://xkcd.com/1827/</a></li>
</ul></li>
</ul>
<div id="example-1-tutoring" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Example 1 Tutoring</h3>
<p>Let us first explore a simple but insightful DAG and reason about interventions and causal effects. Assume the model for the causal relationship between grade <span class="math inline">\(Z\)</span>, tutoring <span class="math inline">\(Y\)</span> and passing the final exam <span class="math inline">\(Y\)</span> is as shown in DAG XXX.</p>
<div class="figure">
<img src="images/dag_exmpl_tut1.png" alt="" />
<p class="caption">DAG1</p>
</div>
<p>More precisely, let’s first look at a deterministic quantitative relation given by</p>
<p><span class="math display">\[\begin{align}
X &amp;:= I(Z &gt;= 4) \\
Y &amp;:= I(Z &lt; 5 \text{ or } (Z = 5 \text{ and } X = 1))
\end{align}\]</span>
i.e. all students with grades 4, 5 or 6 get tuturing (but no students with grades 3 or better); students with grades 4 or better are all passing the exam, whether or not getting tutored, as well as tutored students with grade 5; untutored students with grade 5 are failing the test as well as all students with grade 6 (tutored or not).
This system is already insightful to show that the causal model entails <em>multiple</em> probabilistic models. First, note that we do not observe any students with grade 5 who fail the test and that every failed student had grade 6. The observed conditional expected values for <span class="math inline">\(Y|Z\)</span> are given in table xx.
Second, we can tell what will happen if we intervene in one or more mechanisms. If we, for example, restrict tutoring to students with grade 6, i.e. <span class="math inline">\(X := I(Z &gt;= 6)\)</span>, all students with grade 5 will fail the exam as well as those with grade 6. But nothing will change for students with grade 4, they still will all pass the exam. Without knowing the causal mechanism, the different behavior of stundents with grade 4 and 5 could not have been predicted. In the observed data, both groups were not distinguishible, neither their relation to tutoring (all got tutored) nor by their exam performance (all passed the exam).</p>
<p>Let’s now make this example a bit more interesting (and slightly more realistic) by abandoning the deterministic nature of the mechanism and using a probabilistic one instead. The graph is then to be xxx.</p>
<div class="figure">
<img src="images/dag_exmpl_tut2.png" alt="" />
<p class="caption">DAG2</p>
</div>
<p>Let’s assume the SCM to be given by
<span class="math display">\[\begin{align}
Z &amp;:= f(U_z) \\
X &amp;:= f(Z, U_x) \\
Y &amp;:= f(X, Z, U_y)
\end{align}\]</span></p>
<p>This results int</p>
<div class="figure">
<img src="images/test.png" alt="" />
<p class="caption">CE1</p>
</div>
</div>
</div>
<div id="randomized-controlled-experiments" class="section level2">
<h2><span class="header-section-number">3.2</span> Randomized Controlled Experiments</h2>
<p>TODO</p>
<div id="assignment-mechanisms" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Assignment Mechanisms</h3>

<div class="definition">
<span id="def:rct_assignment" class="definition"><strong>(#def:rct_assignment) (Complete Randomization)  </strong></span>If intervention <span class="math inline">\(X\)</span> is assigned through mechansim
<span class="math display">\[\begin{equation}
X := U
\end{equation}\]</span>
where <span class="math inline">\(U ~ Bernoulli(p)\)</span> with <span class="math inline">\(0 &lt; p &lt; 1\)</span>, the experiment is said to be completely randomized.
</div>

<p>text</p>

<div class="definition">
<span id="def:strat_assignment" class="definition"><strong>(#def:strat_assignment) (Stratified Randomization)  </strong></span>tbd
</div>

<p>Stratified experiments first group individuals according to some observable attribute (e.g. by gender or by city). These groups are called strata. Within each stratum, treatment assignment follows a copmpletey randomized experiment. All methods for statistical inference can be used if the stratum is interpreted as the population for each sub-experiment. In many cases, however, we’re not primarily interested in the effect in each stratum (although this can be informative) but in the population containing all strata. The statistics become more cumbersome, but stratification imposes no harm in the sense of additional assumptions as the stratification mechanism is fully known.</p>
</div>
</div>
<div id="observational-data" class="section level2">
<h2><span class="header-section-number">3.3</span> Observational Data</h2>
<p>We will take a close look at a classic problem that occurs when we try to infer causal statements from observational data.
The basic model that we use is the three-node model, where a variable <span class="math inline">\(Z\)</span> is expected to be a confounder for the causal relation of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, see graph xxx</p>
<div class="figure">
<img src="images/dag_confounder.png" alt="" />
<p class="caption">DAG</p>
</div>
<p>In the most simple case, <span class="math inline">\(Z\)</span>, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are all binary and the SCM <span class="math inline">\(\Gamma\)</span> consists of
<span class="math display">\[\begin{align}
X &amp;:= f_1(Z, V) \\
Y &amp;:= f_2(X, Z, U)
\end{align}\]</span>
and exogeneous variables <span class="math inline">\(Z, V, U\)</span> are mutually independent.</p>
<p>A classic application of this problem occurs in epidemiology, where patients self-select into treatment <span class="math inline">\(X\)</span>, where certain risk factors <span class="math inline">\(Z\)</span> determine the health outcome <span class="math inline">\(Y\)</span> as well as their decision to get treatment <span class="math inline">\(X\)</span>. If observed data that was generated by such a process is used to make inferences about the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, comparing conditional expectations <span class="math inline">\(E[Y|X = 1] - E[Y|X = 0]\)</span> will lead to incorrect conclusions about the (average) causal effect.</p>
<p>To make this clear, let us walk through this example step-by-step to clarify this argument.
First, note that the intervention we are interested in can be described by the graph below</p>
<div class="figure">
<img src="images/dag_confounder_intervention.png" alt="" />
<p class="caption">DAG</p>
</div>
<p>and a change in the structural assignment of <span class="math inline">\(X\)</span>
<span class="math display">\[\begin{equation}
X := 1
\end{equation}\]</span>
in the case of treatment of the entire population (<span class="math inline">\(\Gamma_1\)</span>) and
<span class="math display">\[\begin{equation}
X := 0
\end{equation}\]</span>
in the case of no treatment (<span class="math inline">\(\Gamma_0\)</span>).</p>
<p>What we’re interested in is <span class="math inline">\(E^{\Gamma_1}[Y] - E^{\Gamma_0}[Y]\)</span>, but the observed data was generated by <span class="math inline">\(\Gamma\)</span> rather than <span class="math inline">\(\Gamma_1\)</span> or <span class="math inline">\(\Gamma_0\)</span>. We not need to figure out how we can still get the right statistics.</p>
<p>For this, follow
<span class="math display">\[\begin{align*}
E^{\Gamma_1}[Y] &amp;= P^{\Gamma_1}(Y = 1) \\
                &amp;= P^{\Gamma_1}(Y = 1, X = 1, Z) \\
                &amp;= P^{\Gamma_1}(Y = 1, X = 1, Z = 1) + \\
                &amp;  P^{\Gamma_1}(Y = 1, X = 1, Z = 0) \\
                &amp;= P^{\Gamma_1}(Y = 1 | X = 1, Z = 1) \cdot P^{\Gamma_1}(X = 1, Z = 1) + \\
                &amp;  P^{\Gamma_1}(Y = 1 | X = 1, Z = 0) \cdot P^{\Gamma_1}(X = 1, Z = 0) \\
                &amp;= P^{\Gamma_1}(Y = 1 | X = 1, Z = 1) \cdot P^{\Gamma_1}(Z = 1) + \\
                &amp;  P^{\Gamma_1}(Y = 1 | X = 1, Z = 0) \cdot P^{\Gamma_1}(Z = 0)
\end{align*}\]</span>
where the last equality holds because in <span class="math inline">\(\Gamma_1\)</span> everyone in the population gets the treatment and therefore
<span class="math display">\[\begin{align*}
P^{\Gamma_1}(X = 1, Z = z) &amp;= P^{\Gamma_1}(Z = z | X = 1) \cdot P^{\Gamma_1}(X = 1) \\
                           &amp;= P^{\Gamma_1}(Z = z | X = 1) \cdot 1
\end{align*}\]</span></p>
<p>So far, we have rewritten <span class="math inline">\(E^{\Gamma_1}[Y]\)</span> using some tricks of probability theory. The key point now is to recognize that <span class="math inline">\(P^{\Gamma_1}(Y = 1 | X = 1, Z = 1)\)</span> describes the mechanism of how the health output is determined by the treatment and the patient’s risk factors. From earlier discussion, we know that mechanisms remain invariant under atomic interventions. Hence,
<span class="math display">\[\begin{align*}
P^{\Gamma_1}(Y = 1 | X = 1, Z = 1) &amp;= P^{\Gamma}(Y = 1 | X = 1, Z = 1) \\
P^{\Gamma_1}(Y = 1 | X = 1, Z = 0) &amp;= P^{\Gamma}(Y = 1 | X = 1, Z = 0) \\
P^{\Gamma_1}(Z = 1)                &amp;= P^{\Gamma}(Z = 1)                \\
P^{\Gamma_1}(Z = 0)                &amp;= P^{\Gamma}(Z = 0)
\end{align*}\]</span>
and therefore
<span class="math display">\[\begin{align*}
E^{\Gamma_1}[Y] &amp;= P^{\Gamma}(Y = 1 | X = 1, Z = 1) \cdot P^{\Gamma}(Z = 1) + \\
                &amp;  P^{\Gamma}(Y = 1 | X = 1, Z = 0) \cdot P^{\Gamma}(Z = 0)
\end{align*}\]</span></p>
<p>Following the same reasoning, we can also derive that
<span class="math display">\[\begin{align*}
E^{\Gamma_0}[Y] &amp;= P^{\Gamma}(Y = 1 | X = 0, Z = 1) \cdot P^{\Gamma}(Z = 1) + \\
                &amp;  P^{\Gamma}(Y = 1 | X = 0, Z = 0) \cdot P^{\Gamma}(Z = 0)
\end{align*}\]</span>
which finally produces
<span class="math display">\[\begin{align*}
ATE &amp;= E^{\Gamma_1}[Y] - E^{\Gamma_0}[Y] \\
    &amp;= P^{\Gamma}(Y = 1 | X = 1, Z = 1) \cdot P^{\Gamma}(Z = 1) + P^{\Gamma}(Y = 1 | X = 1, Z = 0) \cdot P^{\Gamma}(Z = 0) - \\
    &amp;  P^{\Gamma}(Y = 1 | X = 0, Z = 1) \cdot P^{\Gamma}(Z = 1) - P^{\Gamma}(Y = 1 | X = 0, Z = 0) \cdot P^{\Gamma}(Z = 0) \\
    &amp;= (P^{\Gamma}(Y = 1 | X = 1, Z = 1) - P^{\Gamma}(Y = 1 | X = 0, Z = 1)) \cdot P^{\Gamma}(Z = 1) + \\
    &amp;  (P^{\Gamma}(Y = 1 | X = 1, Z = 0) - P^{\Gamma}(Y = 1 | X = 0, Z = 0)) \cdot P^{\Gamma}(Z = 0)
\end{align*}\]</span>
In words, the ATE can be calculated from the observational data by comparing the average outcome of treated and non-treated individuals <em>within each risk group</em> <span class="math inline">\(Z\)</span>, and then weigthing these within-group comparisons by the proportion of individuals in each risk group.</p>
<p>Obsiously, this is different from the naive group comparison of treated and non-treated patients</p>
<p><span class="math display">\[\begin{equation}
E^{\Gamma}[Y|X = 1] - E^{\Gamma}[Y|X = 0] = P^{\Gamma}(Y = 1 | X = 1) - P^{\Gamma}(Y = 1 | X = 0)
\end{equation}\]</span>
which therefore does not provide the ATE.</p>
<p>In some cases, this can lead to the phenomenon known as Simpson’s paradox, where the different metrics have differnt sign.</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(Y = 1 / Y=0\)</span></th>
<th><span class="math inline">\(Z = 0\)</span></th>
<th><span class="math inline">\(Z = 1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(X = 0\)</span></td>
<td>260/400</td>
<td>55/100</td>
</tr>
<tr class="even">
<td><span class="math inline">\(X = 1\)</span></td>
<td>70/100</td>
<td>240/400</td>
</tr>
</tbody>
</table>
<p>For the data shown int table xxx
<span class="math display">\[\begin{equation}
E^{\Gamma_1}[Y] - E^{\Gamma_0}[Y] = (\frac{240}{400} - \frac{55}{100}) \frac{500}{1000} + (\frac{70}{100} - \frac{260}{400}) \frac{500}{1000} = (0.6 - 0.55) 0.5 + (0.7 - 0.65) 0.5 = 0.05
\end{equation}\]</span></p>
<p>whereas
<span class="math display">\[\begin{equation}
E^{\Gamma}[Y | X = 1] - E^{\Gamma}[Y | X = 0] = (\frac{310}{500} - \frac{315}{500}) = 0.62 - 0.63 = -0.01
\end{equation}\]</span></p>
</div>
<div id="instrumental-variables" class="section level2">
<h2><span class="header-section-number">3.4</span> Instrumental Variables</h2>
<p>In many practical applications, the assignment cannot be enforced, e.g. patients assigned to take a drug might choose to not follow through. In these cases, the effect of assignment and the effect of the actual treatment (the drug) will be different. A drug might be effective, if the application is difficult, many patients might choose not to follow through. A less effective drug that is easier to apply might have overall higher effectiveness of the assignment.</p>
<p>We can extend graph x from the previous section to show this mechanism explicitly. So far, we have focused on the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, ignoring the details of the mechanism, especially that <span class="math inline">\(Z\)</span>, the patient’s decision to follow the assignment, is a <em>mediator</em> of the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. This is not a problem if the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> is our primary interest. However, we might be interested to split this mechanism into two sub-mechanisms in their own right. The mechanism <span class="math inline">\(X -&gt; Z\)</span> explains how assignment of treatment is followed through by patients, whereas <span class="math inline">\(Z -&gt; Y\)</span> is the biochemical of the drug. Often, researchers are interested in the latter, but aren’t able to enforce assignment. As <span class="math inline">\(U\)</span> is a confounder of <span class="math inline">\(Z -&gt; Y\)</span>, the correlation of <span class="math inline">\(Z\)</span> and <span class="math inline">\(Y\)</span> is not a valid method to estimate the causal effect. In comes the instrumental variable, in this case <span class="math inline">\(X\)</span>.
The intuition behind this method is as follows. We can reliably infer the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, as <span class="math inline">\(X\)</span> is randomized and therefore there is no confounding. We can further also infer the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Z\)</span>, again because <span class="math inline">\(X\)</span> is randomized. In a sense, as <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> is the combined effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Z\)</span> and <span class="math inline">\(Z\)</span> on <span class="math inline">\(Y\)</span>, there are ways we can get the latter from the former two (it is, in general, not just the difference of these two).</p>
<p>TODO</p>
</div>
<div id="propensity-score-matching" class="section level2">
<h2><span class="header-section-number">3.5</span> Propensity Score Matching</h2>
<p>Many questions cannot be answered with deliberate experiments. Experimentation might be considered unethical or unfeasible; the intervention has already been done without randomization;
TODO</p>
</div>
<div id="difference-in-difference-estimator" class="section level2">
<h2><span class="header-section-number">3.6</span> Difference-in-Difference Estimator</h2>
<p>TODO</p>
</div>
<div id="time-series-methods" class="section level2">
<h2><span class="header-section-number">3.7</span> Time Series Methods</h2>
<p>TODO</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>As most (macro-)economic data are time-series, the econometrics literature is full of methods to establish causality in time-series. Most of it goes beyond the description provided in section xxx but unfortunately there are currently on few sources that cover this material in the language and notation of causality adopted here. See also <a href="https://xkcd.com/925/" class="uri">https://xkcd.com/925/</a>.<a href="methods-for-causal-inference.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>This problem is common in the search for heterogeneity in treatment effects, where e.g. the effectiveness of drug is broken down by patient groups (e.g. male vs female, with prior indication vs without). If the number of groups available to the researcher increases, the likelihood of a false discovery increases without proper control. See also <a href="https://xkcd.com/882/" class="uri">https://xkcd.com/882/</a>.<a href="methods-for-causal-inference.html#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="causal-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="applications.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/flobrez/itc/edit/master/causal-inference.md",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
