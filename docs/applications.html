<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Applications | Introduction To Causality: A Modern Approach</title>
  <meta name="description" content="A gentle introduction into the art and science of causal inference" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Applications | Introduction To Causality: A Modern Approach" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://flobrez.github.io/intro_to_causality/" />
  
  <meta property="og:description" content="A gentle introduction into the art and science of causal inference" />
  <meta name="github-repo" content="flobrez/itc" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Applications | Introduction To Causality: A Modern Approach" />
  
  <meta name="twitter:description" content="A gentle introduction into the art and science of causal inference" />
  

<meta name="author" content="Florian Brezina" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="methods-for-causal-inference.html"/>
<link rel="next" href="epistemology.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="itc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Introduction To Causality</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#what-you-will-learn"><i class="fa fa-check"></i><b>1.1</b> What you will learn</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#what-you-wont-learn"><i class="fa fa-check"></i><b>1.2</b> What you won’t learn</a><ul>
<li class="chapter" data-level="1.2.1" data-path="introduction.html"><a href="introduction.html#statistics"><i class="fa fa-check"></i><b>1.2.1</b> Statistics</a></li>
<li class="chapter" data-level="1.2.2" data-path="introduction.html"><a href="introduction.html#machine-learning"><i class="fa fa-check"></i><b>1.2.2</b> Machine Learning</a></li>
<li class="chapter" data-level="1.2.3" data-path="introduction.html"><a href="introduction.html#proofs"><i class="fa fa-check"></i><b>1.2.3</b> Proofs</a></li>
<li class="chapter" data-level="1.2.4" data-path="introduction.html"><a href="introduction.html#type-causality-vs-actual-causality"><i class="fa fa-check"></i><b>1.2.4</b> Type Causality vs Actual Causality</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#how-this-book-is-organised"><i class="fa fa-check"></i><b>1.3</b> How this book is organised</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#prerequisites"><i class="fa fa-check"></i><b>1.4</b> Prerequisites</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#acknowledgements"><i class="fa fa-check"></i><b>1.5</b> Acknowledgements</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#links"><i class="fa fa-check"></i><b>1.6</b> Links</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="defining-causality.html"><a href="defining-causality.html"><i class="fa fa-check"></i><b>2</b> Defining Causality</a><ul>
<li class="chapter" data-level="2.1" data-path="defining-causality.html"><a href="defining-causality.html#causality-asymmetry-and-entropy"><i class="fa fa-check"></i><b>2.1</b> Causality, Asymmetry and Entropy</a></li>
<li class="chapter" data-level="2.2" data-path="defining-causality.html"><a href="defining-causality.html#causal-models"><i class="fa fa-check"></i><b>2.2</b> Causal Models</a><ul>
<li class="chapter" data-level="2.2.1" data-path="defining-causality.html"><a href="defining-causality.html#causal-graphs"><i class="fa fa-check"></i><b>2.2.1</b> Causal Graphs</a></li>
<li class="chapter" data-level="2.2.2" data-path="defining-causality.html"><a href="defining-causality.html#structural-equations"><i class="fa fa-check"></i><b>2.2.2</b> Structural Equations</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="defining-causality.html"><a href="defining-causality.html#causality-in-a-simple-environment"><i class="fa fa-check"></i><b>2.3</b> Causality In A Simple Environment</a></li>
<li class="chapter" data-level="2.4" data-path="defining-causality.html"><a href="defining-causality.html#causality-in-a-complex-environment"><i class="fa fa-check"></i><b>2.4</b> Causality In A Complex Environment</a></li>
<li class="chapter" data-level="2.5" data-path="defining-causality.html"><a href="defining-causality.html#causal-effects"><i class="fa fa-check"></i><b>2.5</b> Causal Effects</a><ul>
<li class="chapter" data-level="2.5.1" data-path="defining-causality.html"><a href="defining-causality.html#definition"><i class="fa fa-check"></i><b>2.5.1</b> Definition</a></li>
<li class="chapter" data-level="2.5.2" data-path="defining-causality.html"><a href="defining-causality.html#causal-effect-statistics"><i class="fa fa-check"></i><b>2.5.2</b> Causal Effect Statistics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html"><i class="fa fa-check"></i><b>3</b> Methods for Causal Inference</a><ul>
<li class="chapter" data-level="3.1" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#causal-vs-statistical-inference"><i class="fa fa-check"></i><b>3.1</b> Causal vs Statistical Inference</a><ul>
<li class="chapter" data-level="3.1.1" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#example-1-tutoring"><i class="fa fa-check"></i><b>3.1.1</b> Example 1 Tutoring</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#randomized-controlled-experiments"><i class="fa fa-check"></i><b>3.2</b> Randomized Controlled Experiments</a><ul>
<li class="chapter" data-level="3.2.1" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#assignment-mechanisms"><i class="fa fa-check"></i><b>3.2.1</b> Assignment Mechanisms</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#instrumental-variables"><i class="fa fa-check"></i><b>3.3</b> Instrumental Variables</a></li>
<li class="chapter" data-level="3.4" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#propensity-score-matching"><i class="fa fa-check"></i><b>3.4</b> Propensity Score Matching</a></li>
<li class="chapter" data-level="3.5" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#difference-in-difference-estimator"><i class="fa fa-check"></i><b>3.5</b> Difference-in-Difference Estimator</a></li>
<li class="chapter" data-level="3.6" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#time-series-methods"><i class="fa fa-check"></i><b>3.6</b> Time Series Methods</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>4</b> Applications</a><ul>
<li class="chapter" data-level="4.1" data-path="applications.html"><a href="applications.html#causality-and-machine-learning"><i class="fa fa-check"></i><b>4.1</b> Causality and Machine Learning</a></li>
<li class="chapter" data-level="4.2" data-path="applications.html"><a href="applications.html#marketing"><i class="fa fa-check"></i><b>4.2</b> Marketing</a></li>
<li class="chapter" data-level="4.3" data-path="applications.html"><a href="applications.html#drug-trial"><i class="fa fa-check"></i><b>4.3</b> Drug Trial</a></li>
<li class="chapter" data-level="4.4" data-path="applications.html"><a href="applications.html#discrimination"><i class="fa fa-check"></i><b>4.4</b> Discrimination</a></li>
<li class="chapter" data-level="4.5" data-path="applications.html"><a href="applications.html#epidemiology"><i class="fa fa-check"></i><b>4.5</b> Epidemiology</a><ul>
<li class="chapter" data-level="4.5.1" data-path="applications.html"><a href="applications.html#the-reporting-mechanism"><i class="fa fa-check"></i><b>4.5.1</b> The reporting mechanism</a></li>
<li class="chapter" data-level="4.5.2" data-path="applications.html"><a href="applications.html#evolving-symptoms"><i class="fa fa-check"></i><b>4.5.2</b> Evolving Symptoms</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="epistemology.html"><a href="epistemology.html"><i class="fa fa-check"></i><b>5</b> Epistemology</a><ul>
<li class="chapter" data-level="5.1" data-path="epistemology.html"><a href="epistemology.html#manipulation"><i class="fa fa-check"></i><b>5.1</b> Manipulation</a></li>
<li class="chapter" data-level="5.2" data-path="epistemology.html"><a href="epistemology.html#long-term-effects"><i class="fa fa-check"></i><b>5.2</b> Long-Term Effects</a></li>
<li class="chapter" data-level="5.3" data-path="epistemology.html"><a href="epistemology.html#are-all-sciences-equal"><i class="fa fa-check"></i><b>5.3</b> Are all sciences equal?</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="notation-and-terminology.html"><a href="notation-and-terminology.html"><i class="fa fa-check"></i><b>A</b> Notation and Terminology</a><ul>
<li class="chapter" data-level="A.1" data-path="notation-and-terminology.html"><a href="notation-and-terminology.html#terminology-confusion"><i class="fa fa-check"></i><b>A.1</b> Terminology Confusion</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="statistics-1.html"><a href="statistics-1.html"><i class="fa fa-check"></i><b>B</b> Statistics</a><ul>
<li class="chapter" data-level="B.1" data-path="statistics-1.html"><a href="statistics-1.html#distributions"><i class="fa fa-check"></i><b>B.1</b> Distributions</a><ul>
<li class="chapter" data-level="B.1.1" data-path="statistics-1.html"><a href="statistics-1.html#single-random-variable"><i class="fa fa-check"></i><b>B.1.1</b> Single Random Variable</a></li>
<li class="chapter" data-level="B.1.2" data-path="statistics-1.html"><a href="statistics-1.html#multiple-random-variables"><i class="fa fa-check"></i><b>B.1.2</b> Multiple Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="statistics-1.html"><a href="statistics-1.html#statistical-inference"><i class="fa fa-check"></i><b>B.2</b> Statistical Inference</a><ul>
<li class="chapter" data-level="B.2.1" data-path="statistics-1.html"><a href="statistics-1.html#estimators"><i class="fa fa-check"></i><b>B.2.1</b> Estimators</a></li>
<li class="chapter" data-level="B.2.2" data-path="statistics-1.html"><a href="statistics-1.html#hypothesis-tests"><i class="fa fa-check"></i><b>B.2.2</b> Hypothesis Tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="code.html"><a href="code.html"><i class="fa fa-check"></i><b>C</b> Code</a><ul>
<li class="chapter" data-level="C.1" data-path="code.html"><a href="code.html#equivalence-of-statistical-properties-and-sql"><i class="fa fa-check"></i><b>C.1</b> Equivalence of statistical properties and SQL</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction To Causality: A Modern Approach</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="applications" class="section level1">
<h1><span class="header-section-number">4</span> Applications</h1>
<div id="causality-and-machine-learning" class="section level2">
<h2><span class="header-section-number">4.1</span> Causality and Machine Learning</h2>
<p>Machine learning has seen many successful applications in recent years. Methods most often employed today belong to the unsupervised and supervised learning paradigm. These methods assume that observed data are identically and independently distributed samples of a (super-) population. For example, supervised learning techniques attempt to learn <span class="math inline">\(Y\)</span> from a set of variables <span class="math inline">\(X\)</span>, i.e. trying to learn <span class="math inline">\(P(Y|X) = f(X)\)</span>.
From the discussion so far it should become clear that only few problems are fit for this paradigm. If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are produced by the same causal/physical system, it should be able to learn the form of <span class="math inline">\(f()\)</span> by collecting lots of data points and fitting algorithms that function class. For example, the “hello world” example of machine learning consists of recognizing handwrittern letters. It is reasonable to assume that this is a rather stable relationship. There aren’t so many different ways people write letters once you’ve seen houndreds of thousands of them. It is also likely that there is no evolution of that relationship, that observervations taken a year ago are not that different from those taken now. It should also be likely that you can transfer this relationship reasonably well between physical systems that do the same or a similar thing, e.g. handwritten letters from tablets vs phones. Transfer will not as well work if the physical system is quite different, e.g. writing with a pen on paper rathen than with a stylus on a digital device.</p>
<p>Many important systems, however, are constantly evolving. It is not reasonable to assume that movie recommendations will be stable over time. Recommending a new show that is currently all the buzz, might not be a good recommendation in a year. Customers who haven’t chosen to see this show yet, might be well aware of the show, but have deliberately decided not to watch it. Using the same trained recommendation model over a prolonged time-period might lead to ever-decreasing model performance and will hence require constant re-training. Models then do not always get better and better over time as information from past observations depreciates in value quite quickly.</p>
<p>Some systems are evolving much quicker than data becomes available. The (world) economy is such a system. Individual behavior and choices are continuously refined and can dramatically change on short notice, while most (macro-) economic data might only be available on a weekly or monthly basis.
Innovation plays an important role. The action set is not fixed over time, but evolves constantly. It can neither be modelled nor predicted (it wouldn’t be an invention then)</p>
</div>
<div id="marketing" class="section level2">
<h2><span class="header-section-number">4.2</span> Marketing</h2>
<p>Another common application where correlation is often confused with causation is in marketing. This might be because data scientist and business might not speak the same language. It might, however, also be a valid pragmatic assumption, which is later validated in an experiment.
I will focus here on the (mis-)application of propensity modeling. Propensity modeling attempts to predict if a (potential) customers will perform a certain action, e.g. whether a new visitor on your site will register or whether a customer will buy a certain product. The model output is an estimated probability that the customer will do the action. Propensity models therefore fall into the class of binary regression.</p>
<p><span class="math display">\[\begin{equation}
P(Y|I) = f(I) \label{eq:mktg1} \tag{1}
\end{equation}\]</span>
where <span class="math inline">\(I\)</span> is the information set available for prediction.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<p>There are plently of algorithms that could be used to estimate the function. Logistic regression is often chosen as it is easy to implement and the model itself might provide some insights. Here, we will focus not on the implementation part, but on the interpretation and (mis-) use of the model.</p>
<p>To see why the model might not be want you think it is, we will have a
A naive usage of the model is to focus marketing on customers with high likelhood to do the action. This however, can be serverly misleading, as we will discuss next. To show this, we will start with an ideal assumption: our model is perfect. A perfect model means that we predict the customer action correctly for every customer and the model produces predicted probabilies which are well calibrated. This means that we only get two predictions, either a customer will do action with estimated probability 0 or whether they will do so with probability 1 - and the model is always right.
However, although we have the best possible model, it illustrates well why the naive interpreation cannot be correct. If we focus our marketing on those customers with highest propensity (as there are only two values it is those with predicted probability 1), we focus our attention on a customer group that buys the product anyways. In fact, these are the customers that we should <em>least</em> focus on as the best we can do is to have no effect on those customers (but we still have the cost of the marketing intervention, which might be an opportunity cost) and in some case we might even affect the customer adversely (as they might be annoyed by the marketing). Hence, we’re left with the second group of customers, those with predicted probability of 0. In this group, there might be some who will be convinced to buy the product after being exposed to the marketing, but we are not able to say which ones. Even after doing an experiment, we will not improve on our decision rule. Say, we run an A/B test on all customers who were predicted to not buy, and we estimate that 0.02
Depending on the situation, this model might not be very useful. The only thing that we learned from the model is that we should exclude those customers with highest probability from our marketing. This runs counter to our intuition. Furthermore, in many applications, the action might be a rare event, with likelihoods not much higher than 1%. Excluding these customers from marketing might not save a lot of money in the first place, and establishing a system where you’re able to provide different marketing on customer-level might have some fixed costs (e.g. it might require to store and process customer-level data and deploy the model-outputs to production systems).</p>
<p></p>
<p>From the example it becomes clear that propensity modelling using a predictive model on passively observed data will at best be a proxy for the problem at hand. The goal of marketing optimization is to optimally trade-off the cost and effect of marketing, where the latter is a <em>causal</em> rather than an assosiative concept. Supervised machine learning models, regardless of their complexity, will fail at achieving the task since even a <em>ideal</em> falls short.
To see this more clearly, let’s restate the problem in causal notation first. Let <span class="math inline">\(Y\)</span> denote the binary customer action we want to predict. Further, let <span class="math inline">\(S\)</span> denote the default environment, which includes all relevant causal factors that determine customer decisions, their preferences and endowment, the offers available on the market and our own offer and current marketing strategy. For simplicity’s sake, let’s assume our marketing strategy is binary and denote it by <span class="math inline">\(M\)</span> (e.g. whether or not we send the customer a marketing email). Assume the current marketing strategy is <span class="math inline">\(M = 0\)</span>, i.e. we do currently not have an email program.
The individual causal differential effect of sending an email to customer <span class="math inline">\(i\)</span> is then
<span class="math display">\[\begin{equation}
\Delta_i := Y_i^{S;do(Z_i:=1)} - Y_i^{S; do(Z_i:=0)} \label{eq:myfirsteq} \tag{1}
\end{equation}\]</span></p>
<p>As <span class="math inline">\(Y\)</span> is binary, <span class="math inline">\(\Delta\)</span> can be one of <span class="math inline">\({-1, 0, 1}\)</span> with <span class="math inline">\(\Delta = 1\)</span> being the desired outcome. As discussed in [causality], we are not able to measure this quantity directly, but need to resort to population-level quantities instead:
<span class="math display">\[\begin{equation}
P(\Delta) = P^{S;do(Z:=1)}(Y) - P^{S;do(Z:=0)}(Y) \label{eq:mktg_pop_ate} \tag{2}
\end{equation}\]</span>
Both quantities on the right-hand side of equation <span class="math inline">\(\eqref{eq:mktg_pop_ate}\)</span> can be estimated. There are couple of ways to do so, many of which we discussed in [causality]. The most straigtforward way is to apply a randomized controlled trial (or “A/B test”) where the population at hand is randomly split in two groups, one group being exposed to the marketing (i.e. <span class="math inline">\(S;do(Z:=1)\)</span>) the other not being exposed (i.e. <span class="math inline">\(S;do(Z:=0)\)</span>).
Conditioning the probability estimate on a set of features allows us to investigate whether the <em>differential causal effect</em> is co-related with observable information - which ultimately tells us who will be most affected by the marketing.
In the most simple case, we condition by a single discrete attribute <span class="math inline">\(A\)</span>, providing
<span class="math display">\[\begin{equation}
P(\Delta | A) = P^{S;do(Z:=1)}(Y | A) - P^{S;do(Z:=0)}(Y | A) \label{eq:mktg_pop_cate} \tag{3}
\end{equation}\]</span></p>
<p>This is superficially similar to equation <span class="math inline">\(\eqref{eq:mktg1}\)</span>, but note that the right-hand side in $ describes two conditional probabilities drawn from two different environments.
It will be helpful to rewrite this into a linear model form. Assume that <span class="math inline">\(A\)</span> is binary. Then
<span class="math display">\[\begin{align}
P(\Delta | A = 1) &amp;= P^{S;do(Z:=1)}(Y | A = 1) - P^{S;do(Z:=0)}(Y | A = 1) \\
                  &amp;= a_1 - a_0 \\
                  &amp;=: \Delta_1 \\
P(\Delta | A = 0) &amp;= P^{S;do(Z:=1)}(Y | A = 0) - P^{S;do(Z:=0)}(Y | A = 0) \\
                  &amp;= a_3 - a_2 \\  
                  &amp;=: \Delta_0           
\end{align}\]</span>
We can further represent <span class="math inline">\(P(Y)\)</span> as a function of <span class="math inline">\(Z\)</span>
<span class="math display">\[\begin{align}
P(Y) &amp;= P^{S;do(Z:=0)}(Y) \cdot (1-Z) + P^{S;do(Z:=1)}(Y) \cdot Z \\
     &amp;= P^{S;do(Z:=0)}(Y) + (P^{S;do(Z:=1)}(Y) - P^{S;do(Z:=0)}(Y)) \cdot Z \\
     &amp;= P^{S;do(Z:=0)}(Y) + P(\Delta) \cdot Z \\
     &amp;= \beta_0 + \beta_1 Z
\end{align}\]</span>
Further, replacing unconditional quantities with conditional ones, we can write
<span class="math display">\[\begin{align}
P(Y | A) &amp;= P^{S;do(Z:=0)}(Y | A) + P(\Delta | A) \cdot Z \\
         &amp;= \alpha_0 + \alpha_1 A + (\Delta_0 + \Delta_1 \cdot A) \cdot Z \\
         &amp;= \alpha_0 + \alpha_1 A + \Delta_0 Z + \Delta_1 A Z
\end{align}\]</span>
which looks quite familiar as it is the conventional way to specify a logistic regression equation on <span class="math inline">\(A\)</span>, <span class="math inline">\(Z\)</span> and the interaction of both <span class="math inline">\(A \cdot Z\)</span>.[^footnote-hte-nomenclature] If the treatment is ineffective <span class="math inline">\(\Delta_0 = 0\)</span> <em>and</em> <span class="math inline">\(Delta_1 = 0\)</span>. The <em>differential causal effect</em> is said to be heterogeneous, if <span class="math inline">\(\Delta_1 \neq 0\)</span>.
[^footnote-hte-nomenclature]: The literature on <em>heterogeneous treatment effect</em> models often groups parameters of this equation regarding their role in application: <span class="math inline">\(\alpha_1\)</span> is called “prognostic” as it shows if and how the success rate differs across attributes <span class="math inline">\(A\)</span> <em>if no intervention/treatment</em> is provided; <span class="math inline">\(\Delta_1\)</span> on the other hand is often called “predictive”, meaning how predictive <span class="math inline">\(A\)</span> is on the <em>effectiveness of the intervention/treatment</em>, i.e. whether and by how much treatment effects differ across values of <span class="math inline">\(A\)</span>.</p>
<p>The model can be generalized to the case where not just a single (binary) attribute is considered, but a vector of attributes.</p>
<p>In a marketing context with binary treatment and outcome, table xxx can be restated as</p>
<table>
<caption><span id="tab:simple-table">Table 4.1: </span> Caption here</caption>
<thead>
<tr class="header">
<th align="right"></th>
<th align="center"><span class="math inline">\(Y^{\Gamma;do(X:=0)} = 0\)</span></th>
<th align="center"><span class="math inline">\(Y^{\Gamma;do(X:=0)} = 1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><span class="math inline">\(Y^{\Gamma;do(X:=1)} = 0\)</span></td>
<td align="center">“Lost Cause”</td>
<td align="center">“Do-Not-Disturb”</td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(Y^{\Gamma;do(X:=1)} = 1\)</span></td>
<td align="center">“Persuadable”</td>
<td align="center">“Sure Things”</td>
</tr>
</tbody>
</table>

</div>
<div id="drug-trial" class="section level2">
<h2><span class="header-section-number">4.3</span> Drug Trial</h2>

</div>
<div id="discrimination" class="section level2">
<h2><span class="header-section-number">4.4</span> Discrimination</h2>
<p>In den letzten Jahren wurde in Politik, Medien und Wissenschaft häufiger über Diskriminierung diskutiert, einige Beispiele sind hierbei die Diskriminierung von Frauen im Berufsleben, der Wahl von Abegordneten zum Bundestag. Ein Verbot von Diskriminierung hat in Deutschland im Jahre 2006 Gesetzescharakter angenommen mit der Verabschiedung des <em>Allgemeinen Gleichbehandlungsgesetzes (AGG)</em>, dass u.a. die Diskriminierung aus Gründen des Alters, der ethnischen Herkunft oder des Geschlechts unzulässig ist. Wie bereits des Gesetzesname andeutet, wird Diskriminierung als ein Vorgang angesehen, nicht als ein Zustand. Dies wird insebesondere in §3 deutlich, wo eine (unmittelbare) Diskriminierung dann vorliegt “wenn eine Person wegen [Alter, Herkunft oder Geschlecht] eine weniger günstige Behandlung erfährt, als eine andere Person in einer vergleichbaren Situation erfährt”.
Die zunehmende Anwendung automatisierter Entscheidungsalgorithmen rückt die Frage nach Diskrimierung auch in den Blickpunkt der Forschung im Bereich des maschinellen Lernens. Es ist in diesem Kontext, dass dieses Thema eine mathematische Formalisierung erfahren hat. Dabei wurden zuletzt auch kausale Argumentationen und Notation eingeführt, siehe etwa Kilbertus etl al..</p>
<p>Wir werden uns im Folgenden an einem einfachen Beispiel diesem Problem nähern sowie einen Versuch der
Die Identifikation von diskriminierenden Handlungen wird dadurch erschwert, dass die Handelnden Personen häufig nur einen Teil des gesamten Mechanismus kontrollieren und es begründete Sachzwänge gibt.
Im Folgenden unterscheiden wir zwei Merkmalstypen</p>
<p>First, let’s introduce some basic terminology first:
* <em>protected feature</em>: this is a person’s feature that is legally protected, e.g. age or gender.
* <em>accepted feature</em>: these are features that are explicitely or implicitely accepted for discrimination, e.g. the job might (by law) require a certain certificate of qualification or the job requires a certain skillset like a specific programming language or the ability to lift weigths heavier than 30 kg.</p>
<p>While the protected features are usually unambiguous and explicitly stated in law, the accepted features can be reason for disagreement. It is usually the set of features that are deemed to be necessary to do the job, but of course “doing the job” can done in different qualities. A bar owner might believe it to be necessary for his waiters to be handsome and flirty with the predominantely female audience, but an applicant might think it is not. Getting the order right and providing the right servcie while being friendly he might consider to be sufficient.</p>
<ul>
<li><p><em>unprotected feature</em>: these are all features that are not explicitly protected, e.g. eye color, ability to lift more than 30kg</p></li>
<li><p><em>zulässige Merkmale</em>: dies sind Merkmale, nach denen eine diskriminierende Handlung zulässig ist. So kann etwa für eine Tätigkeit in einem Warenlager voraussgesetzt werden, dass ein Bewerber in der Lage sein muss, Lasten über 20kg zu transportieren, da dies für die Erfüllung der Tätigkeit unabdingbar ist.</p></li>
<li><p><em>aufhebende Merkmale</em>: diese stellen eine Teilmenge der <em>zulässigen Merkmale</em> dar. Es sind diejenigen Merkmale, die auf dem kausalen Pfad zwischen den <em>geschützten</em> Merkmalen und dem Output liegen. Das Merkmal “kann Lasten über 20kg transportieren” ist vermutlich ein solches, da dieses kausal vom Geschlecht und/oder dem Alter eines Bewerbers beeinflusst ist.</p></li>
<li><p><em>unzulässige Merkmale</em>: sind Merkmale, nach denen eine diskriminierende Handlung nicht zulässig ist, die aber nicht ein <em>geschütztes Merkmal</em> sind. Dies könnte etwa die Augenfarbe des Bewerbers sein, die (etwa gemäß AGG nicht geschützt ist), jedoch für die Erfüllung der Tätigkeit irrelevant sein dürfte.</p></li>
<li><p><em>stellvertretende Merkmale</em>: diese stellen eine Teilmenge der <em>unzulässigen Merkmale</em> dar. Es sind diejenige Merkmale, die auf dem kausalen Pfad zwischen den <em>geschützten</em> Merkmalen und dem Output liegen. So kann die Augenfarbe eines Bewerbers ein <em>stellvertretendes Merkmal</em> sein, wenn die Augenfarbe etwa durch das Geschlecht oder die ethnische Herkunft beeinflusst wird. Sie werden <em>stellvertretend</em> genannt, da sie Information über das geschützte Merkmals beinhalten und somit zur Diskriminierung herangezogen werden könnten.</p></li>
</ul>
<p>TODO: sollte <em>unzulässig</em> nicht anders bezeichnet werden, da ja eine Diskriminierung nach nicht-stellvertretern rechtlich nicht verboten ist.</p>
<p>Es gelten folgende Definitionen:</p>
<ul>
<li>kann ein Mechanismus der unmittelbaren Diskriminierung durch einen vom geschützten Merkmal unabhängigen Prozess (oder eine Konstante) ersetzt werden, ohne dass sich die Verteilung der Zielvariable ändert, so ist dieser Mechanismus nicht-diskriminierend</li>
</ul>

</div>
<div id="epidemiology" class="section level2">
<h2><span class="header-section-number">4.5</span> Epidemiology</h2>
<p>Inspired by the 2020 SARS-CoV-2 epidemic, let’s have a look at a causal model for understanding the high-level epidemiological data that was widely discussed at the time. We want to focus on the causal mecheanisms that generate the number of reported infections and the impact on non-pharmacological interventions.
The model will illustrate that it is crucially important to understand the causal mechanisms when interpreting statistics, as differences (say across countries or compared between epidemics) might be misleading if this is not accounted for.</p>
<p>For simplicity, we will present the causal graph as a summary graph, where we neglect the inherent time structure of the mechanism. This does not cause any problems for causal reasoning, as the summary graph is still acyclic. However, to make inferences based on observed data, we will later on take a look at the full time graph as well.</p>
<div id="the-reporting-mechanism" class="section level3">
<h3><span class="header-section-number">4.5.1</span> The reporting mechanism</h3>
<p>extra text</p>
<div class="figure">
<img src="images/dag_app_epidem1.png" alt="" />
<p class="caption">DAG55</p>
</div>
<p>We model the reporting mechanism as follows:</p>
<ul>
<li>for a person to be reported to be infected with SARS-CoV-2, there are two main causal influneces: whether the person is in fact infected with that virus and whether a PCR test was performed. If we assume that test used is perfect (i.e. has no type I error nor a type II error), we can model this relationship deterministically as <span class="math inline">\(ReportedInfection := f(Test, Infection)\)</span>. Note that the assumption of a perfect test also allows us to disregard any causal influence from <span class="math inline">\(OtherInfection\)</span> to <span class="math inline">\(ReportedInfection\)</span>, which would be the case if the test accidently would show positive outcomes in cases where the person does not have SARS-CoV-2, but a similar infection (e.g. other corona viruses).</li>
<li>a person is tested for SARS-CoV-2 if they are symptomatic and/or have had recent contact with a person known to be SARS-CoV-2-positive. Again, for simplicity, we assume that this is a strict rule-based (and stable) mechanism.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> The structural assigment is <span class="math inline">\(Test := g(Symptoms, ContactInfected)\)</span>.</li>
</ul>
<ul>
<li><p>a person’s symptoms are determined by them being infected by the SARS-Cov-2 virus, other viruses causing respiratory diseases, age, pre-existing conditions, as well as other unspecified and unobserved factors (e.g. genetics). The assignment is <span class="math inline">\(Symptoms := h(Infection, InfectionOther, Age, PreCondition, U)\)</span>, and the assignment is probabilistic to to <span class="math inline">\(U\)</span> being treated as a noise term. As we define symptoms to include the value “death”, this mechanisms has to fully explain a person’s likelihood to die with and without the virus.</p></li>
<li><p>the infection mechanism is modelled as a probablistic function of personal hygiene and exposure to the virus: <span class="math inline">\(Infection := h(Hygiene, Exposure, V)\)</span></p></li>
<li><p>finally, a person is reported to have died of SARS-CoV-2 if the person has been positively tested for the virus and has died (one of the possible values of the symptom): <span class="math inline">\(ReportedDeath := h(ReportedInfection, Symptoms)\)</span>. We assume this to be a simple and determinsitic mechanism.</p></li>
</ul>
<div id="reasoning-about-interventions-and-counterfactuals" class="section level4">
<h4><span class="header-section-number">4.5.1.1</span> Reasoning about interventions and counterfactuals</h4>
<p>The model now allows us to reason about certain interventions that affect the reported numbers of infected and deceased.</p>
<div id="no-virus" class="section level5">
<h5><span class="header-section-number">4.5.1.1.1</span> No virus</h5>
<p>The most important one is certainly the counterfactual question of what would happen if there were no SARS-CoV-2 virus out there, which serves as a baseline model that allows us to compare the pandemic situation to a “normal” one.
Technically, this amounts to replacing the assignment for variable <span class="math inline">\(Infection\)</span> to
<span class="math display">\[\begin{equation}
Infection := 0
\end{equation}\]</span>
As this is just a hypothetical intervention, let us assume that it is atomic, i.e. we assume that the rest of the model is not changed by this intervention. Most importantly, the assignment <span class="math inline">\(Symptoms := h(Infection, InfectionOther, Age, PreCondition, U)\)</span> is still in place, it’s just that the value of one of the inputs is <span class="math inline">\(0\)</span> in the entire population.
As <span class="math inline">\(Symptoms\)</span> was defined to be a categorical variable including the value “death”, we can use the model to compare two distributions in the population, one with and one without the virus. The difference tells us the additional deaths due to SARS-CoV-2 virus rather than just the numer of deaths associated with SARS-CoV-2 (which is what <span class="math inline">\(ReportedDeath\)</span> is capturing). This information is important because we ultimately want to understand how deadly the disease acutally is, i.e. how many deaths it causes, not just how prevalent it is in people how are dying. With the median age of reported deaths with the virus being at around 80 and the probability of a person at 80 to die within 12 months being at around 5%, this is non-negligible.</p>
</div>
<div id="changing-testing-strategy" class="section level5">
<h5><span class="header-section-number">4.5.1.1.2</span> Changing testing strategy</h5>
<p>expanding test capacities
comparing numbers across countries with (very) different test strategies
random testing</p>
</div>
</div>
</div>
<div id="evolving-symptoms" class="section level3">
<h3><span class="header-section-number">4.5.2</span> Evolving Symptoms</h3>
<p>To model the evolution of symptoms over time, we need to switch from a time series summary graph to a full time graph.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>Typically you will find a notation similar to <span class="math inline">\(P(Y|X) = f(X)\)</span> where <span class="math inline">\(X\)</span> is called a feature set or a vector/matrix of features. I use the term information set to deliberately distinguish between the notion of all the information you have available for a customer. The information set is abstract and represents information in potentially very different formats, e.g. order data in your data base, the recorded call with the customer service team, or the customer’s product reviews. Feature engineering is the step where this information is transformed into a format that can be used by ML algorithms: the order data could be transformed into multiple features, e.g. the total revenue in past 30 days, total revenue in past 180 days, the number of days the customer put an order in; the recorded call can transformed into days since the latest customer service contanct, length of the call, length of waiting in line and whether or not the issue was resolved; the product reviews are transformed into word embeddings.<a href="applications.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>In reality, this assumption was violated. Over the course of the epidemic, testing capabilities have increased in most countries and tests have been expanded over time. In some countries and regions, asymptomatic persons have been tested as well, even if there was no known contact with another infected person. We discuss this in more detail when we take a look at the full time graph of the model.<a href="applications.html#fnref7" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="methods-for-causal-inference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="epistemology.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/flobrez/itc/edit/master/app_marketing.md",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
