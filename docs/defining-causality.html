<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 Defining Causality | Introduction To Causality: A Modern Approach</title>
  <meta name="description" content="A gentle introduction into the art and science of causal inference" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="2 Defining Causality | Introduction To Causality: A Modern Approach" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://flobrez.github.io/intro_to_causality/" />
  
  <meta property="og:description" content="A gentle introduction into the art and science of causal inference" />
  <meta name="github-repo" content="flobrez/itc" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Defining Causality | Introduction To Causality: A Modern Approach" />
  
  <meta name="twitter:description" content="A gentle introduction into the art and science of causal inference" />
  

<meta name="author" content="Florian Brezina" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="methods-for-causal-inference.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="itc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Introduction To Causality</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#what-you-will-learn"><i class="fa fa-check"></i><b>1.1</b> What you will learn</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#how-this-book-is-organised"><i class="fa fa-check"></i><b>1.2</b> How this book is organised</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#what-you-wont-learn"><i class="fa fa-check"></i><b>1.3</b> What you won’t learn</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introduction.html"><a href="introduction.html#statistics"><i class="fa fa-check"></i><b>1.3.1</b> Statistics</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction.html"><a href="introduction.html#machine-learning"><i class="fa fa-check"></i><b>1.3.2</b> Machine Learning</a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction.html"><a href="introduction.html#proofs"><i class="fa fa-check"></i><b>1.3.3</b> Proofs</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#prerequisites"><i class="fa fa-check"></i><b>1.4</b> Prerequisites</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#acknowledgements"><i class="fa fa-check"></i><b>1.5</b> Acknowledgements</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#links"><i class="fa fa-check"></i><b>1.6</b> Links</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="defining-causality.html"><a href="defining-causality.html"><i class="fa fa-check"></i><b>2</b> Defining Causality</a><ul>
<li class="chapter" data-level="2.1" data-path="defining-causality.html"><a href="defining-causality.html#causal-models"><i class="fa fa-check"></i><b>2.1</b> Causal Models</a></li>
<li class="chapter" data-level="2.2" data-path="defining-causality.html"><a href="defining-causality.html#causality-in-simple-environments"><i class="fa fa-check"></i><b>2.2</b> Causality in simple environments</a></li>
<li class="chapter" data-level="2.3" data-path="defining-causality.html"><a href="defining-causality.html#causality-in-complex-environments"><i class="fa fa-check"></i><b>2.3</b> Causality in complex environments</a></li>
<li class="chapter" data-level="2.4" data-path="defining-causality.html"><a href="defining-causality.html#measuring-causal-effects"><i class="fa fa-check"></i><b>2.4</b> Measuring causal effects</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html"><i class="fa fa-check"></i><b>3</b> Methods for Causal Inference</a><ul>
<li class="chapter" data-level="3.1" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#causal-vs-statistical-inference"><i class="fa fa-check"></i><b>3.1</b> Causal vs Statistical Inference</a></li>
<li class="chapter" data-level="3.2" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#randomized-controlled-experiments"><i class="fa fa-check"></i><b>3.2</b> Randomized Controlled Experiments</a></li>
<li class="chapter" data-level="3.3" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#instrumental-variables"><i class="fa fa-check"></i><b>3.3</b> Instrumental Variables</a></li>
<li class="chapter" data-level="3.4" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#propensity-score-matching"><i class="fa fa-check"></i><b>3.4</b> Propensity Score Matching</a></li>
<li class="chapter" data-level="3.5" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#difference-in-difference-estimator"><i class="fa fa-check"></i><b>3.5</b> Difference-in-Difference Estimator</a></li>
<li class="chapter" data-level="3.6" data-path="methods-for-causal-inference.html"><a href="methods-for-causal-inference.html#time-series-methods"><i class="fa fa-check"></i><b>3.6</b> Time Series Methods</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>4</b> Applications</a><ul>
<li class="chapter" data-level="4.1" data-path="applications.html"><a href="applications.html#marketing"><i class="fa fa-check"></i><b>4.1</b> Marketing</a></li>
<li class="chapter" data-level="4.2" data-path="applications.html"><a href="applications.html#drug-trial"><i class="fa fa-check"></i><b>4.2</b> Drug Trial</a></li>
<li class="chapter" data-level="4.3" data-path="applications.html"><a href="applications.html#discrimination"><i class="fa fa-check"></i><b>4.3</b> Discrimination</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="epistemology.html"><a href="epistemology.html"><i class="fa fa-check"></i><b>5</b> Epistemology</a><ul>
<li class="chapter" data-level="5.1" data-path="epistemology.html"><a href="epistemology.html#manipulation"><i class="fa fa-check"></i><b>5.1</b> Manipulation</a></li>
<li class="chapter" data-level="5.2" data-path="epistemology.html"><a href="epistemology.html#long-term-effects"><i class="fa fa-check"></i><b>5.2</b> Long-Term Effects</a></li>
<li class="chapter" data-level="5.3" data-path="epistemology.html"><a href="epistemology.html#are-all-sciences-equal"><i class="fa fa-check"></i><b>5.3</b> Are all sciences equal?</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="notation-and-terminology.html"><a href="notation-and-terminology.html"><i class="fa fa-check"></i><b>A</b> Notation and Terminology</a></li>
<li class="chapter" data-level="B" data-path="statistics-1.html"><a href="statistics-1.html"><i class="fa fa-check"></i><b>B</b> Statistics</a><ul>
<li class="chapter" data-level="B.1" data-path="statistics-1.html"><a href="statistics-1.html#distributions"><i class="fa fa-check"></i><b>B.1</b> Distributions</a><ul>
<li class="chapter" data-level="B.1.1" data-path="statistics-1.html"><a href="statistics-1.html#single-random-variable"><i class="fa fa-check"></i><b>B.1.1</b> Single Random Variable</a></li>
<li class="chapter" data-level="B.1.2" data-path="statistics-1.html"><a href="statistics-1.html#multiple-random-variables"><i class="fa fa-check"></i><b>B.1.2</b> Multiple Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="statistics-1.html"><a href="statistics-1.html#statistical-inference"><i class="fa fa-check"></i><b>B.2</b> Statistical Inference</a><ul>
<li class="chapter" data-level="B.2.1" data-path="statistics-1.html"><a href="statistics-1.html#estimators"><i class="fa fa-check"></i><b>B.2.1</b> Estimators</a></li>
<li class="chapter" data-level="B.2.2" data-path="statistics-1.html"><a href="statistics-1.html#hypothesis-tests"><i class="fa fa-check"></i><b>B.2.2</b> Hypothesis Tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="code.html"><a href="code.html"><i class="fa fa-check"></i><b>C</b> Code</a><ul>
<li class="chapter" data-level="C.1" data-path="code.html"><a href="code.html#equivalence-of-statistical-properties-and-sql"><i class="fa fa-check"></i><b>C.1</b> Equivalence of statistical properties and SQL</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction To Causality: A Modern Approach</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="defining-causality" class="section level1">
<h1><span class="header-section-number">2</span> Defining Causality</h1>
<div id="causal-models" class="section level2">
<h2><span class="header-section-number">2.1</span> Causal Models</h2>
<p>We assume the world can be modelled by <em>variables</em>. Variables can take various values. The variables themselves are denoted by upper-case latin letters, e.g. <span class="math inline">\(X\)</span>, whereas we use lower-case letters for their values, e.g. <span class="math inline">\(x\)</span>. In case <span class="math inline">\(X\)</span> is <em>categorical</em>, different values will be denoted by a subscript <span class="math inline">\(x_j\)</span>. Where <span class="math inline">\(X\)</span> has two values only, we will encode them with <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>.</p>
<p><em>Structural equations</em> represent the causal relations between <em>variables</em>. The <em>absence</em> of a variable from the model assumes that it is not relevant for the causal description of the system.
We will focus exposition on <em>categorical variables</em> which can assume a</p>
<p><span class="math inline">\(X \rightarrow Y\)</span> means that <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>. Manipulating <span class="math inline">\(X\)</span> determines the value of <span class="math inline">\(Y\)</span>, but not the other way round. We call <span class="math inline">\(X\)</span> the <em>cause</em> and <span class="math inline">\(Y\)</span> the <em>outcome</em>. Others call <span class="math inline">\(Y\)</span> the “<em>effect</em>”, but we will use <em>effect</em> to denote changes in the outcome due to manipulations of the cause. This is in line with conventions in statistical literature (e.g. “average treatment effect”) and its usage in everyday language (e.g. “tipping on that button had no effect on the brightness of the screen”).</p>
</div>
<div id="causality-in-simple-environments" class="section level2">
<h2><span class="header-section-number">2.2</span> Causality in simple environments</h2>
<p>Let’s first take a look at a maximally simple environment, shown in figure xxx. It represents a circuit diagram with a voltage source, a switch (X) and a lamp (Y). All elements of this environment can assume one of two states each, which we will conveniently encode as 0 and 1:
* the switch can either be open (0) or closed (1)
* the lamp can either be off (0) or on (1).
Let’s further assume that the voltage source has enough capacity to lighten the lamp if the switch is closed. Although this system is easy to understand and reason about, let’s take an extra second to translate the circuit diagram into a <em>causal graph</em>, a representation that will become quite handy in more complex environments that will be discussed later in the book.</p>

<div class="theorem">
<span id="thm:graphs" class="theorem"><strong>Theorem 2.1  (Causal Graphs)  </strong></span>A graph is a mathematical structure. It consists of a set of nodes and and a set of edges, where edges connect ordered pairs of nodes. In <em>causal graphs</em>, nodes represent variables; edges represent the causal relation from cause to effect. Note that in a causal graph, an edge is an <em>ordered</em> pair of nodes, the edge therefore directed. In most graphs in this book, we will consider causal systems that can be represeted as directed acyclical graphs (DAGs).
</div>

<p>We can further represent a <em>causal graph</em> as a set of structural equations. Due to its simplicity, the circuit diagram can be represented with a single equation:
<span class="math display">\[\begin{equation}
Y := f(X) = X
\end{equation}\]</span>
Note, that the equation uses operator “<span class="math inline">\(:=\)</span>”" rather than the usual “<span class="math inline">\(=\)</span>”. It reads “<span class="math inline">\(f(X)\)</span> is evaluated and <em>assigned</em> to <span class="math inline">\(Y\)</span>” and therefore resembles variable assignment in many programming languages where, for example, <code>x = x + 1</code> is a valid expression. Crucially, it is asymmetric: if <span class="math inline">\(X\)</span> is the air temperature and <span class="math inline">\(Y\)</span> the reading of the temperature on a thermometer, the reading will change if we heat up the air; manipulating the reading, e.g. by exposing the thermometer to direct sunlight will not heat up the air around it.</p>
<p>Since the structural equation represents the <em>causal mechanism</em> relating the switch and the lamp, we can immediately read what happens if we intervene on the switch: when we close the switch, i.e. <span class="math inline">\(do(X:= 1)\)</span>, then the lamp will be on, <span class="math inline">\(Y := 1\)</span>; if we open the switch, <span class="math inline">\(do(X:= 0)\)</span>, then the lamp dies, <span class="math inline">\(Y := 0\)</span>.</p>
<p>Let’s take it up a notch and create a more interesting environment by adding a second switch, connected in series, see figure XXX for the circuit diagram and figure xxx for the graph representation. The two switches allow the environment to be in four different states. Only if both switches are on, will the lamp be on, in the other three states it will be off:</p>
<table>
<thead>
<tr class="header">
<th>switch <span class="math inline">\(X_1\)</span></th>
<th>switch <span class="math inline">\(X_2\)</span></th>
<th>lamp <span class="math inline">\(Y\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="odd">
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>We can easily spot that the structural equation representation is
<span class="math display">\[\begin{equation}
Y := f(X_1, X_2) = X_1 \cdot X_2
\end{equation}\]</span></p>
<p>Setzen wir in diesem System nun den Schalter 1 auf geschlossen, erkennen wir, dass der Zustand der Leuchte nun noch vom Zustand des zweiten Schalters abhängt.
<span class="math display">\[\begin{equation}
Y := f(1, X_2) = 1 \cdot X_2 = X_2
\end{equation}\]</span></p>
<p>Nehmen wir nun an, dass wir nicht allwissend sind, sondern sich ein Schleier des Unwissens über Schalter 2 gelegt hat: wir wissen, dass es ihn gibt, wir wissen nur nicht, ob dieser geschlossen ist oder nicht.</p>
<p>Man stellt uns nun die Aufgabe, den Zustand des Schalters 2 aus der rein passiven Beobachtung des Systems zu lernen.</p>
<p>Ein Blick auf Tabelle xxx zeigt, dass uns das nur in einigen Fällen gelingen wird. Bestimmte Konstellationen von Schalter 1 und Leuchte geben uns nicht ausreichende Information, um den Zustand von Schalter 2 lernen zu können. Selbstverständlich könnten wir dieses Problem lösen, indem wir Schalter 1 betätigen und beobachten, wie sich Leuchte dann ändert. Tatsächlich können wir durch die Intervention und die weitere Beobachtung auf den Zustand von Schalter 2 zu schließen.</p>
<p>Dies ist bereits ein erster Hinweis auf ein fundamentales Problem, auf das wir im Weiteren noch detaillierter eingehen werden: durch Interventionen in eine System können Informationen generiert werden, die aus rein passiver Beobachtung nicht verfügbar sind.</p>
<p>Gehen wir nun noch einen Schritt weiter und überlegen wir uns, ob das Problem gelöst werden kann, indem wir</p>
</div>
<div id="causality-in-complex-environments" class="section level2">
<h2><span class="header-section-number">2.3</span> Causality in complex environments</h2>
<p><span class="math display">\[\begin{equation}
\Delta_i := Y_i^{S;do(Z_i:=1)} - Y_i^{S; do(Z_i:=0)} \label{eq:myfirsteq} \tag{1}
\end{equation}\]</span></p>
<p>As <span class="math inline">\(Y\)</span> is binary, <span class="math inline">\(\Delta\)</span> can be one of <span class="math inline">\({-1, 0, 1}\)</span> with <span class="math inline">\(\Delta = 1\)</span> being the desired outcome. As discussed in [causality], we are not able to measure this quantity directly, but need to resort to population-level quantities instead:
<span class="math display">\[\begin{equation}
P(\Delta) = P^{S;do(Z:=1)}(Y) - P^{S;do(Z:=0)}(Y) \label{eq:mktg_pop_ate} \tag{2}
\end{equation}\]</span></p>
</div>
<div id="measuring-causal-effects" class="section level2">
<h2><span class="header-section-number">2.4</span> Measuring causal effects</h2>
<p>The fundamental problem of causal inference</p>
<p>The definition of [causal effect] hints at a severe problem for its measurements. It involves two quantities which can never be both observed at once. This poses a problem, a problem so fundamental that is often called <strong>the fundamental problem of causal inference</strong>.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="methods-for-causal-inference.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/flobrez/itc/edit/master/causality.md",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
