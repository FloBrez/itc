# Epistemology

## Are all sciences equal?

The concept of causality as discussed in this book is a cornerstone of many scientific disciplines. Although in most cases not stated explicitly in those terms, the question **what will happen if i does x (versus y)** is implicit in most scientific work in diverse fields such as economics, psychology, medicine, and history\footnote{For history, the question needs to be changed to **what would have happened if i did x (versus y)**. Note that *i* needs to be an actor who can *manipulate x* directly for this question to make sense. Statements such as *if it weren't for Mikhail Gorbachev, the Soviet Union wouldn't have been dissolved in '91* are therefore too ambiguous for a rigorous treatment: it will likely matter if Gorbachev wasn't elected by the Politburo in 1985 in the first place, being ousted from office by coup d'Ã©tat or stepped down from office due to health reasons.}.
The interventions contemplated and analyzed in these disciplines vary widely in terms of manipulability, scope and ethics: a randomized experiment on fiscal policy is neither operationally feasible nor ethically desirable - at least at a the level of entire nations; assessing how individuals provide different answers if questions are phrased differently is both manipulable in a controlled environment and too unintrusive to be ethically problematic. Throughout the book we discussed several methods to infer causal relationships ranging from randomized controlled trials to time series analysis. With every step away from the ideal properties of an RCT, the reliability and robustness of results crucially depended on the validity of the assumptions that we were willing to accept. In general, the more assumptions we make, the more likely the results will be unreliable.
On a sidenote: of course, incorrect causal assumptions are not the only or even the main reason for scientific results to be unreliable. Many of those have to do with problems of *statisical inference* instead. Even in experiments following an RCT design, there are plenty of pitfalls to be aware of. Too small samples, p-hacking, and publishing bias are just a few reasons for the [replication crisis](https://en.wikipedia.org/wiki/Replication_crisis) in psychology, medicine and other social sciences.

Least reliable results are to be expected when the complexity of the subject matter is very high, but the methodoligal toolkit to investigate it is reduced to the least reliable ones

* macroeconomics. growth, business cycle, monetary and fiscal policy.
* epidemiology. including nutrition.
* social psychology.
* evolution. while the theory of evolution has strong empirical support, combinatorial explosion and complex dynamics do not allow for a reliable inference of effects of interventions in the biosphere.

Even if complexity is high, if some aspects of the problem can be thoroughly studied and combined using a consistent theory, the overall results can be reasonably reliable:

* climate science.
* microeconomics. pseudo-experiments on price controls (e.g. minimum wage or gas price cap) supported by strong theory of supply and demand. problem is often quantification of effects rather than the general direction. There is almost no disagreement across labor economists that there exists a general trade-off between higher minimum wages and lower unemployment. The debate today primarily focuses on the possibility of small negative or even positive effects on employment, but virtually everybody accepts the logic that unemployment will exist/increase above a certain threshold.
*


*
